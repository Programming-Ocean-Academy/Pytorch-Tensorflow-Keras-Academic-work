{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![images.webp](data:image/webp;base64,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)\n",
        "# Adam Paszke\n"
      ],
      "metadata": {
        "id": "XNUI4JGSTbSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch: An Imperative Style, High-Performance Deep Learning Library  \n",
        "*(arXiv:1912.01703v1)*\n",
        "\n",
        "# https://arxiv.org/pdf/1912.01703\n",
        "\n",
        "## Abstract\n",
        "The paper introduces **PyTorch**, a deep learning framework designed to unify **usability** and **performance**. PyTorch employs an imperative, Python-native execution model with dynamic computation graphs while achieving performance comparable to static-graph frameworks. The work details the system architecture, runtime optimizations, and backend design that enable efficient CPU and GPU execution, and empirically demonstrates competitive performance across widely used deep learning benchmarks.\n",
        "\n",
        "## Problems\n",
        "\n",
        "### Usability vs. Performance Trade-off\n",
        "Prior deep learning frameworks typically favor either developer productivity through dynamic execution or high performance through static graphs, but struggle to provide both simultaneously.\n",
        "\n",
        "### Limited Flexibility of Static Graphs\n",
        "Static dataflow graphs restrict dynamic control flow, complicate debugging, and slow experimentation with novel or adaptive model architectures.\n",
        "\n",
        "### Python Performance Constraints\n",
        "Python interpreter overhead and the Global Interpreter Lock (GIL) pose challenges for high-throughput execution in large-scale deep learning workloads.\n",
        "\n",
        "## Proposed Solutions\n",
        "\n",
        "### Imperative “Define-by-Run” Execution\n",
        "PyTorch models are expressed as standard Python programs and executed eagerly, enabling full language expressiveness, intuitive debugging, and flexible control flow.\n",
        "\n",
        "### High-Performance C++ Backend (libtorch)\n",
        "Performance-critical components—tensor operations, automatic differentiation, and parallel primitives—are implemented in C++ to avoid Python bottlenecks.\n",
        "\n",
        "### Runtime and Memory Optimizations\n",
        "The system integrates asynchronous GPU execution, a custom CUDA memory allocator, reference-counted memory management, and multiprocessing support to reduce overhead while preserving flexibility.\n",
        "\n",
        "## Purpose\n",
        "The primary goal is to demonstrate that **dynamic, Pythonic deep learning frameworks can achieve state-of-the-art performance**. The paper documents the architectural and implementation choices that allow PyTorch to reconcile ease of use with computational efficiency.\n",
        "\n",
        "## Methodology\n",
        "\n",
        "### Design Principles\n",
        "- Python-first and researcher-centric design  \n",
        "- Emphasis on productivity and debuggability  \n",
        "- Pragmatic performance optimizations  \n",
        "- Preference for simple, composable abstractions  \n",
        "\n",
        "### System Architecture\n",
        "- Control flow handled in Python; data flow executed in optimized C++ kernels  \n",
        "- Reverse-mode automatic differentiation via operator overloading  \n",
        "- GPU acceleration through asynchronous CUDA streams  \n",
        "\n",
        "### Evaluation\n",
        "PyTorch is evaluated on standard models and workloads, including AlexNet, VGG-19, ResNet-50, MobileNet, GNMTv2, and Neural Collaborative Filtering (NCF), and compared against TensorFlow, MXNet, CNTK, and Chainer.\n",
        "\n",
        "## Results\n",
        "- PyTorch achieves throughput within approximately **17% of the fastest competing framework** across all benchmarks.  \n",
        "- Near-optimal GPU utilization is achieved through overlap of CPU scheduling and GPU execution.  \n",
        "- The custom CUDA memory allocator significantly reduces runtime overhead after warm-up iterations.  \n",
        "- Adoption metrics show rapid and sustained growth in the research community.\n",
        "\n",
        "## Conclusions\n",
        "The paper establishes that an **imperative, dynamic execution model** can coexist with **high-performance deep learning**. By combining Python-level flexibility with a carefully engineered C++ runtime, PyTorch delivers both productivity and efficiency. Its design choices have driven widespread adoption in research, and future directions emphasize further optimization through JIT compilation and enhanced distributed and parallel computing capabilities.\n"
      ],
      "metadata": {
        "id": "Ld20GKPwS2Qe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a **focused extraction and explanation of all mathematical and statistical content** in the paper, written from a mathematician’s perspective and limited strictly to concepts that play a functional role in the work.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Tensors and Multidimensional Arrays\n",
        "\n",
        "### Concept\n",
        "\n",
        "A **tensor** is a multidimensional array, generalizing scalars (0-D), vectors (1-D), and matrices (2-D).\n",
        "\n",
        "### Role in the Paper\n",
        "\n",
        "- Tensors are the fundamental mathematical objects manipulated by PyTorch.  \n",
        "- All computations (forward evaluation, gradient propagation, GPU kernels) operate on tensors.  \n",
        "- PyTorch follows the array-based numerical computing paradigm established by NumPy and MATLAB.\n",
        "\n",
        "### Mathematical View\n",
        "\n",
        "A tensor can be viewed as an element of the Cartesian product space\n",
        "\n",
        "$$\n",
        "\\mathbb{R}^{n_1 \\times n_2 \\times \\dots \\times n_k}\n",
        "$$\n",
        "\n",
        "where each axis corresponds to a semantic dimension such as batch size, channels, or features.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Automatic Differentiation (Autograd)\n",
        "\n",
        "### Concept\n",
        "\n",
        "**Automatic differentiation (AD)** computes exact derivatives of functions represented as programs by systematically applying the chain rule.\n",
        "\n",
        "### Role in the Paper\n",
        "\n",
        "- PyTorch implements **reverse-mode automatic differentiation**.  \n",
        "- Gradients are constructed dynamically during execution (“define-by-run”).\n",
        "\n",
        "### Mathematical Explanation\n",
        "\n",
        "Given a scalar loss function\n",
        "\n",
        "$$\n",
        "L = f(x_1, x_2, \\dots, x_n),\n",
        "$$\n",
        "\n",
        "reverse-mode AD computes all partial derivatives\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial x_i}, \\quad i = 1, \\dots, n.\n",
        "$$\n",
        "\n",
        "This mode is computationally efficient when:\n",
        "- the output is scalar, and  \n",
        "- the input dimension is large (the standard setting in deep learning).\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Vector–Jacobian Products (VJP)\n",
        "\n",
        "### Concept\n",
        "\n",
        "Rather than forming Jacobian matrices explicitly, PyTorch computes **vector–Jacobian products**.\n",
        "\n",
        "### Mathematical Formulation\n",
        "\n",
        "Let\n",
        "\n",
        "- \\( f : \\mathbb{R}^n \\rightarrow \\mathbb{R}^m \\),\n",
        "- \\( J = \\dfrac{\\partial f}{\\partial x} \\) be the Jacobian,\n",
        "- \\( v \\in \\mathbb{R}^m \\).\n",
        "\n",
        "The quantity computed is\n",
        "\n",
        "$$\n",
        "v^\\top J.\n",
        "$$\n",
        "\n",
        "### Role in the Paper\n",
        "\n",
        "- This is the core mathematical primitive underlying PyTorch’s autograd engine.  \n",
        "- It avoids explicit Jacobian construction, reducing both memory usage and computational cost.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Forward-Mode vs. Reverse-Mode Differentiation\n",
        "\n",
        "### Concepts\n",
        "\n",
        "- **Forward-mode AD** propagates derivatives from inputs to outputs.  \n",
        "- **Reverse-mode AD** propagates derivatives from outputs back to inputs.\n",
        "\n",
        "### Mathematical Trade-off\n",
        "\n",
        "| Mode        | Computationally Efficient When |\n",
        "|------------|--------------------------------|\n",
        "| Forward    | Few inputs, many outputs       |\n",
        "| Reverse    | Many inputs, single output     |\n",
        "\n",
        "### Role in the Paper\n",
        "\n",
        "- PyTorch adopts reverse-mode AD because training typically minimizes a scalar loss.  \n",
        "- Forward-mode AD is acknowledged but not central to the framework’s design.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Differentiation Through Mutation\n",
        "\n",
        "### Concept\n",
        "\n",
        "Differentiation of programs that perform **in-place mutation** on tensors.\n",
        "\n",
        "### Mathematical Challenge\n",
        "\n",
        "Mutation violates the assumption of pure functional composition required for naïve application of the chain rule.\n",
        "\n",
        "### PyTorch’s Mathematical Safeguard\n",
        "\n",
        "- Each tensor maintains a **version counter**.  \n",
        "- Gradients are computed only if the dependency graph remains mathematically valid.\n",
        "\n",
        "### Role in the Paper\n",
        "\n",
        "- Enables differentiation of realistic imperative programs.  \n",
        "- Prevents invalid gradient computation caused by overwritten values.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Linear Algebra Operations\n",
        "\n",
        "### Examples\n",
        "\n",
        "- Affine transformation:\n",
        "\n",
        "$$\n",
        "Y = XW + b\n",
        "$$\n",
        "\n",
        "- Convolutions  \n",
        "- Elementwise nonlinearities (e.g., ReLU, softmax)\n",
        "\n",
        "### Role in the Paper\n",
        "\n",
        "- Demonstrates that PyTorch operations correspond to standard linear-algebraic primitives.  \n",
        "- Confirms that neural network layers are constructed from well-defined mathematical operations.\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Gradient-Based Optimization\n",
        "\n",
        "### Concept\n",
        "\n",
        "Model parameters are updated using gradient-based optimization algorithms.\n",
        "\n",
        "### Mathematical Form\n",
        "\n",
        "A generic gradient descent update is\n",
        "\n",
        "$$\n",
        "\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta L,\n",
        "$$\n",
        "\n",
        "where \\( \\eta \\) is the learning rate.\n",
        "\n",
        "### Role in the Paper\n",
        "\n",
        "- Optimizers (e.g., Adam) rely directly on gradients produced by autograd.  \n",
        "- Optimization is implemented as ordinary Python code operating on tensors.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Asynchronous Execution and Scheduling (Implicit Mathematics)\n",
        "\n",
        "### Concept\n",
        "\n",
        "CPU scheduling and GPU execution are overlapped asynchronously.\n",
        "\n",
        "### Mathematical Interpretation\n",
        "\n",
        "This corresponds to **pipeline parallelism**, which improves throughput without altering the underlying numerical computation.\n",
        "\n",
        "### Role in the Paper\n",
        "\n",
        "- Ensures high hardware utilization while preserving numerical correctness.\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Memory Management and Reference Counting (Quantitative Aspect)\n",
        "\n",
        "### Concept\n",
        "\n",
        "Tensors are deallocated immediately when their reference count reaches zero.\n",
        "\n",
        "### Mathematical Relevance\n",
        "\n",
        "- Prevents unnecessary memory growth, which otherwise constrains feasible batch sizes and tensor dimensions.  \n",
        "- Enables large-scale numerical optimization problems to remain computationally tractable.\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Benchmark Metrics (Statistical Content)\n",
        "\n",
        "### Metrics Used\n",
        "\n",
        "- Throughput measures such as:\n",
        "  - images per second,\n",
        "  - tokens per second,\n",
        "  - samples per second.\n",
        "\n",
        "### Statistical Interpretation\n",
        "\n",
        "- Performance results are reported as mean values with variability across repeated runs.  \n",
        "- Comparisons are performed under controlled hardware and software conditions.\n",
        "\n",
        "### Role in the Paper\n",
        "\n",
        "- Quantitatively demonstrates that dynamic execution incurs only modest overhead.\n",
        "\n",
        "---\n",
        "\n",
        "## 11. Adoption Statistics\n",
        "\n",
        "### Metric\n",
        "\n",
        "- Fraction of arXiv papers mentioning PyTorch over time.\n",
        "\n",
        "### Statistical Role\n",
        "\n",
        "- Serves as a proxy measure for usability and community adoption.  \n",
        "- Shows monotonic growth relative to alternative frameworks.\n",
        "\n",
        "---\n",
        "\n",
        "## Overall Mathematical Perspective\n",
        "\n",
        "The paper introduces **no new mathematical theory**. Its contribution lies in:\n",
        "\n",
        "- Applying established mathematics (tensors, differential calculus, linear algebra, numerical optimization),  \n",
        "- Embedding these tools in a **dynamic, imperative computational framework**, and  \n",
        "- Preserving mathematical correctness while improving practical usability.\n",
        "\n",
        "The novelty is fundamentally **engineering-driven**, yet firmly grounded in classical numerical analysis and multivariate calculus.\n"
      ],
      "metadata": {
        "id": "4aePy7VKTGUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structured Review of Research Gaps and Contributions\n",
        "\n",
        "| Key Problem / Research Gap | How This Limited Prior Work | Proposed Solution in This Paper |\n",
        "|---------------------------|-----------------------------|---------------------------------|\n",
        "| Trade-off between usability and performance | Static-graph frameworks (e.g., TensorFlow, CNTK) achieved high performance but were difficult to debug, inflexible, and poorly suited to dynamic model structures; dynamic frameworks often sacrificed speed | Introduces PyTorch as an imperative, eager-execution framework that preserves Python flexibility while achieving performance comparable to static-graph systems |\n",
        "| Rigid static computation graphs | Static graphs constrained control flow (loops, conditionals, recursion), making it difficult to implement novel or adaptive model architectures | Adopts a define-by-run model where computation graphs are built dynamically during execution, fully supporting arbitrary Python control flow |\n",
        "| Difficulty of debugging deep learning models | Prior frameworks required graph compilation or specialized debugging tools, preventing inspection of intermediate values during execution | Treats models as standard Python programs, enabling direct use of print statements, debuggers, and visualization tools |\n",
        "| Performance overhead of Python execution | Python’s interpreter overhead and Global Interpreter Lock limited concurrency and throughput in dynamic frameworks | Implements a high-performance C++ core (libtorch) that executes tensor operations, autograd, and parallelism outside the Python interpreter |\n",
        "| Inefficient gradient computation for dynamic programs | Source-to-source differentiation or graph rewriting was brittle or infeasible in highly dynamic languages | Uses operator overloading with reverse-mode automatic differentiation to compute gradients exactly for arbitrary executed programs |\n",
        "| Poor GPU utilization in eager frameworks | CPU-side scheduling overhead often prevented full GPU saturation | Employs asynchronous GPU execution via CUDA streams, overlapping CPU control flow with GPU computation |\n",
        "| GPU memory allocation overhead | Frequent `cudaMalloc` / `cudaFree` calls caused synchronization stalls and degraded performance | Introduces a custom CUDA caching allocator optimized for deep learning memory usage patterns |\n",
        "| Limited extensibility of framework components | Many frameworks imposed rigid APIs, making it difficult to replace or customize core components | Designs all subsystems (autograd, data loading, optimizers) to be modular and user-replaceable |\n",
        "| Inefficient multiprocessing for tensor data | Standard Python multiprocessing incurred heavy serialization overhead for large arrays | Extends Python multiprocessing to share tensor memory efficiently, including transparent CUDA tensor sharing |\n",
        "| Excessive memory usage due to garbage collection | Garbage-collected systems delayed memory reclamation, limiting feasible batch sizes on GPUs | Uses reference counting to deterministically free tensor memory as soon as it becomes unused |\n",
        "| Lack of empirical validation of eager execution performance | Dynamic frameworks were often assumed to be inherently slower without rigorous benchmarking | Provides systematic benchmarks showing PyTorch performance within approximately $$17\\%$$ of the fastest competing frameworks |\n",
        "| Unclear real-world adoption impact | Usability claims were often anecdotal or qualitative | Quantifies community adoption via arXiv mentions, demonstrating rapid and sustained growth |\n",
        "\n",
        "---\n",
        "\n",
        "## Summary Insight\n",
        "\n",
        "The paper systematically addresses long-standing tensions between **flexibility**, **debuggability**, and **performance** in deep learning frameworks. Its core contribution is not a new learning algorithm, but a **runtime and system design** that enables mathematically standard deep learning methods to be expressed dynamically—via imperative programs and reverse-mode automatic differentiation—without incurring prohibitive computational cost.\n"
      ],
      "metadata": {
        "id": "IblDm61DTPKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Related Work Extracted from the Reference Section\n",
        "\n",
        "| Author(s) | Year | Title | Venue | Connection to This Paper |\n",
        "|---------|------|-------|-------|--------------------------|\n",
        "| Jia et al. | 2014 | *Caffe: Convolutional Architecture for Fast Feature Embedding* | arXiv | Representative static-graph deep learning framework; illustrates performance-focused but less flexible design compared to PyTorch |\n",
        "| Seide & Agarwal | 2016 | *CNTK: Microsoft’s Open-Source Deep-Learning Toolkit* | KDD | Example of a high-performance static graph framework that trades usability and flexibility for efficiency |\n",
        "| Abadi et al. | 2015 | *TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems* | Software (Google) | Canonical static dataflow framework; serves as a primary comparison point for PyTorch’s eager execution model |\n",
        "| Theano Development Team | 2016 | *Theano: A Python Framework for Fast Computation of Mathematical Expressions* | arXiv | Early symbolic graph-based framework influencing later static computation graph designs |\n",
        "| Tokui et al. | 2015 | *Chainer: A Next-Generation Open Source Framework for Deep Learning* | NIPS Workshop | Pioneer of define-by-run (dynamic) execution; directly motivates PyTorch’s imperative programming model |\n",
        "| Neubig et al. | 2017 | *DyNet: The Dynamic Neural Network Toolkit* | arXiv | Dynamic neural network framework highlighting benefits of eager execution but limited by performance and ecosystem |\n",
        "| Collobert et al. | 2002 | *Torch: A Modular Machine Learning Software Library* | Technical Report (IDiap) | Predecessor framework emphasizing modularity and numerical computing; influences PyTorch’s tensor abstraction |\n",
        "| Collobert et al. | 2011 | *Torch7: A MATLAB-like Environment for Machine Learning* | NeurIPS | Lua-based deep learning framework whose performance and modular design informed PyTorch’s C++ backend |\n",
        "| Baydin et al. | 2017 | *Automatic Differentiation in Machine Learning: A Survey* | JMLR | Provides theoretical background for automatic differentiation used by PyTorch’s autograd system |\n",
        "| Maclaurin | 2016 | *Modeling, Inference and Optimization with Composable Differentiable Procedures* | PhD Thesis (Harvard) | Influences composable, operator-overloading-based differentiation strategies |\n",
        "| Johnson et al. | 2018 | *JAX* | GitHub / Software | Modern NumPy-based automatic differentiation system; represents parallel evolution of dynamic AD frameworks |\n",
        "| Innes et al. | 2018 | *Flux.jl* | GitHub / Software | Julia-based dynamic deep learning framework; supports the feasibility of imperative ML systems |\n",
        "| Chetlur et al. | 2014 | *cuDNN: Efficient Primitives for Deep Learning* | arXiv | Provides GPU-optimized kernels leveraged by PyTorch for high-performance execution |\n",
        "| Lavin & Gray | 2016 | *Fast Algorithms for Convolutional Neural Networks* | CVPR | Underpins optimized convolution implementations used by modern deep learning frameworks |\n",
        "| Recht et al. | 2011 | *Hogwild: A Lock-Free Approach to Parallelizing SGD* | NeurIPS | Motivates PyTorch’s multiprocessing and shared-memory parallel training capabilities |\n",
        "\n",
        "---\n",
        "\n",
        "## Synthesis\n",
        "\n",
        "The related work spans three principal categories:\n",
        "\n",
        "1. **Static computation graph frameworks**, emphasizing performance and compiler-based optimization but limiting flexibility and debuggability.  \n",
        "2. **Dynamic, define-by-run systems**, prioritizing expressiveness and ease of experimentation but historically constrained by performance and tooling.  \n",
        "3. **Foundational numerical and systems research**, including automatic differentiation theory, GPU-accelerated linear algebra, and parallel optimization methods.\n",
        "\n",
        "PyTorch positions itself as a unifying system that combines the **imperative flexibility** of dynamic frameworks with the **computational efficiency** traditionally associated with static-graph systems. This synthesis is enabled by advances in reverse-mode automatic differentiation, optimized C++ runtimes, and high-performance GPU libraries, rather than by the introduction of new learning algorithms.\n"
      ],
      "metadata": {
        "id": "_TCB7tjKTSWI"
      }
    }
  ]
}